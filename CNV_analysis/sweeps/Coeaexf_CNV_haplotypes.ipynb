{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haplotype analysis *Coeaexg*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color palettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dictionary of pop colors\n",
    "pop_colours = {\n",
    " 'Moshi' : \"lightgreen\",\n",
    " 'Muleba' : \"darkgreen\",\n",
    "}\n",
    "\n",
    "dup_colours = {\n",
    "    'Dup present' : 'mediumorchid',\n",
    "    'Dup absent' : 'lightgray',\n",
    "    '4 extra copies': 'purple',\n",
    "    '3 extra copies': 'mediumorchid',\n",
    "    '2 extra copies': 'orange',\n",
    "    '1 extra copy': 'pink',\n",
    "    'No CNV': 'lightgray'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malariagen_data\n",
    "import allel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy.cluster\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CNV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Ag1000G_CNV_data/v3.7_1246-VO-TZ-KABULA-VMF00185/target_regions_analysis/focal_region_CNV_table_extras.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30082/142510510.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Identify samples that have Cyp6_Dup31\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdisc_cnv_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../Ag1000G_CNV_data/v3.7_1246-VO-TZ-KABULA-VMF00185/target_regions_analysis/focal_region_CNV_table_extras.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdiscordant_read_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_cnv_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mhas_Dup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscordant_read_calls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Coeaexf_Dup2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mDup_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhas_Dup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Ag1000G_CNV_data/v3.7_1246-VO-TZ-KABULA-VMF00185/target_regions_analysis/focal_region_CNV_table_extras.csv'"
     ]
    }
   ],
   "source": [
    "# Identify samples that have Cyp6_Dup31\n",
    "disc_cnv_fn = '../Ag1000G_CNV_data/v3.7_1246-VO-TZ-KABULA-VMF00185/target_regions_analysis/focal_region_CNV_table.csv'\n",
    "discordant_read_calls = pd.read_csv(disc_cnv_fn, sep = '\\t', index_col = 0)\n",
    "has_Dup = discordant_read_calls['Coeaexf_Dup2'].values\n",
    "Dup_calls = has_Dup.astype('int')\n",
    "\n",
    "# In order to known the copy number of each Dup specifically, we need to ignore samples that also\n",
    "# have another CNV. \n",
    "other_coeaexf_cnvs = (\n",
    "    discordant_read_calls.columns.str.contains('Coeaexf') &\n",
    "    ~discordant_read_calls.columns.str.contains('Dup0') &\n",
    "    ~discordant_read_calls.columns.str.contains('Dup2') \n",
    ")\n",
    "other_coeaexf_calls = discordant_read_calls.loc[:, other_coeaexf_cnvs]\n",
    "has_other_coeaexf_cnv = np.sum(other_coeaexf_calls, 1).values > 0\n",
    "\n",
    "# Now we can exclude samples that have both the focal and another CNV allele, or that have the \n",
    "# allele and are of high coverage variance (because we won't be able to assign copy number correctly)\n",
    "exclude_samples = (  \n",
    "    has_Dup & (\n",
    "        has_other_coeaexf_cnv | \n",
    "        discordant_read_calls[\"High.var.sample\"]\n",
    "    )                  \n",
    ").values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag3 = malariagen_data.Ag3(pre=True)\n",
    "\n",
    "sample_sets = ['1246-VO-TZ-KABULA-VMF00185']\n",
    "meta = ag3.sample_metadata(sample_sets = sample_sets).set_index('sample_id')\n",
    "meta['location'] = meta['location'].str.replace('_.*', '', regex=True)\n",
    "\n",
    "# Make sure the samples are in the same order as the CNV data (they should be anyway, but \n",
    "# just in case)\n",
    "meta = meta.loc[discordant_read_calls.index, :]\n",
    "\n",
    "# Get haplotype-level metadata\n",
    "hap_meta = pd.DataFrame(np.repeat(meta.values, 2, axis = 0))\n",
    "hap_meta.columns = meta.columns\n",
    "hap_meta.index = [np.repeat(meta.index, 2)[i] + ['a', 'b'][i%2] for i in range(len(hap_meta))]\n",
    "\n",
    "hap_meta_Dup = hap_meta.loc[~np.repeat(exclude_samples, 2), :]\n",
    "\n",
    "hap_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gene_copy_number = pd.read_csv('../Ag1000G_CNV_data/v3.7_1246-VO-TZ-KABULA-VMF00185/modal_CNVs/modal_copy_number_arabiensis.csv', sep = '\\t', index_col = 0)\n",
    "\n",
    "# Define genes of interest\n",
    "coeaexf_genes = dict(AGAP006227='Coeae1f',\n",
    "                     AGAP006228='Coeae2f')\n",
    "\n",
    "# Select data for genes of interest, excluding samples with poor quality HMM data\n",
    "coeae2f_gene_copy_number = (\n",
    "    gene_copy_number.loc[:, coeaexf_genes.keys()]\n",
    "    .rename(coeaexf_genes, axis='columns')\n",
    ")['Coeae2f'].values\n",
    "\n",
    "Dup_copy_number = coeae2f_gene_copy_number[~exclude_samples] * Dup_calls[~exclude_samples]\n",
    "\n",
    "display(pd.crosstab(meta.loc[~exclude_samples, 'location'], Dup_copy_number))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The copy number can get above 2, so probably isn't a simple duplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the haplotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region='2L:28300000-28800000'\n",
    "\n",
    "haps = (\n",
    "    ag3.haplotypes(region = region, \n",
    "                   analysis = 'arab', \n",
    "                   sample_sets = sample_sets)\n",
    "    .set_index(samples = 'sample_id')\n",
    "    .sel(samples = discordant_read_calls.index)\n",
    ")\n",
    "\n",
    "haps_Dup = haps.isel(samples = ~exclude_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create haplotype array\n",
    "hap_array_Dup = allel.GenotypeArray(haps_Dup.call_genotype).to_haplotypes()\n",
    "\n",
    "# Get allele counts\n",
    "ac = hap_array_Dup.count_alleles()\n",
    "\n",
    "# Identify segregating non-singletons. \n",
    "non_singleton = ac.min(1) > 1\n",
    "\n",
    "# Filter the datasets, removing non-segregating and singleton variants \n",
    "haps_Dup = haps_Dup.isel(variants = np.where(non_singleton)[0])\n",
    "hap_array_Dup = hap_array_Dup[non_singleton]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SNP genotypes coded as 0, 1, 2 (wt, het, homozygote mutant). Since all phased SNPs\n",
    "# are biallelic, this is a suitable way to code genotype. \n",
    "genotypes = haps_Dup.call_genotype.values.sum(2)\n",
    "genotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify proxy SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We look for SNPs whose presence / absence patterns are perfectly correlated with Dup31. \n",
    "SNP_cor = np.apply_along_axis(lambda x: spearmanr((x>0).astype('int'), \n",
    "                                                  Dup_calls[~exclude_samples]), \n",
    "                                    1, \n",
    "                                    genotypes)[:, 0]\n",
    "SNP_cor = np.abs(SNP_cor)\n",
    "print(f'The maximum correlation coefficient with the Dup is {np.nanmax(SNP_cor)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Dup_proxy = genotypes[np.nanargmax(SNP_cor)]\n",
    "\n",
    "# Let's look at the association of zygosity at those SNPs and copy number. \n",
    "\n",
    "print('Association of Dup2 proxy zygosity and Dup2 copy number in Moshi:')\n",
    "display(\n",
    "    pd.crosstab(Dup_copy_number[(meta.loc[~exclude_samples, :].location == 'Moshi').values],\n",
    "                Dup_proxy[(meta.loc[~exclude_samples, :].location == 'Moshi').values])\n",
    ")\n",
    "\n",
    "print('Association of Dup2 proxy zygosity and Dup2 copy number in Muleba:')\n",
    "display(\n",
    "    pd.crosstab(Dup_copy_number[(meta.loc[~exclude_samples, :].location == 'Muleba').values],\n",
    "                Dup_proxy[(meta.loc[~exclude_samples, :].location == 'Muleba').values])\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a half decent proxy, but produces both false positive and false negatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the haplotypes rather than genotypes for the Dup2 proxy\n",
    "Dup_hap_proxy = hap_array_Dup[np.nanargmax(SNP_cor)]\n",
    "Dup_hap_proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haplotype plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters(dist, n, threshold=0.001, method='complete'):\n",
    "        # build hierarchy\n",
    "        clust = scipy.cluster.hierarchy.linkage(dist, method=method)\n",
    "        # find clusters\n",
    "        f = scipy.cluster.hierarchy.fcluster(clust, threshold,\n",
    "                                             criterion='distance')\n",
    "        # compute cluster sizes\n",
    "        fsz = np.bincount(f)\n",
    "        # sort largest first\n",
    "        fsort = np.argsort(fsz)[::-1]\n",
    "        # take largest n\n",
    "        fsort = fsort[:n]\n",
    "        # get haplotype indices for each cluster\n",
    "        clusters = [set(np.nonzero(f == i)[0]) for i in fsort]\n",
    "        return clusters\n",
    "\n",
    "# Some plotting functions\n",
    "def truspan(cluster, r):\n",
    "    # get the index of the cluster haps in the dendrogram list of all haps\n",
    "    cluster_leaves = sorted([r['leaves'].index(i) for i in cluster])\n",
    "    # are these indices monotonic - they should be!\n",
    "    x = np.asarray(cluster_leaves)\n",
    "    dx = np.diff(x)\n",
    "    mon = np.all(dx == 1)\n",
    "    assert mon\n",
    "    return min(cluster_leaves), max(cluster_leaves)\n",
    "\n",
    "def plot_dendrogram(zhier, ax, h, method='complete', color_threshold=0, above_threshold_color='k'):\n",
    "\n",
    "    # plot dendrogram\n",
    "    sns.despine(ax=ax, offset=5, bottom=True, top=False)\n",
    "    r = scipy.cluster.hierarchy.dendrogram(zhier, no_labels=True, count_sort=True,\n",
    "                                           color_threshold=color_threshold,\n",
    "                                           above_threshold_color=above_threshold_color,\n",
    "                                           ax=ax)\n",
    "    xmin, xmax = ax.xaxis.get_data_interval()\n",
    "    xticklabels = np.array(list(range(0, h.shape[1], 200)) + [h.shape[1]])\n",
    "    xticks = xticklabels / h.shape[1]\n",
    "    xticks = (xticks * (xmax - xmin)) + xmin\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "    #ax.set_xlabel('Haplotypes')\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.set_ylim(bottom=-.0001)\n",
    "\n",
    "    ax.set_ylabel(r'$d_{xy}$')\n",
    "    ax.autoscale(axis='x', tight=True)\n",
    "    return r\n",
    "\n",
    "def draw_hap_cluster_plot(z, r, h, \n",
    "                          pop_colour_scheme, cnv_colour_scheme, \n",
    "                          labels_for_pop_colours, labels_for_cnv_colours, \n",
    "                          cnv_name,\n",
    "                          add_legend = True, title = '',\n",
    "                          fn = None):\n",
    "\n",
    "    gs = GridSpec(3, 1, height_ratios=[6.0, 0.5, 0.5])\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.02)\n",
    "    ax1 = plt.subplot(gs[0])\n",
    "    sns.despine(ax=ax1, offset=5, bottom=True, top=True)\n",
    "    _ = plot_dendrogram(z, ax1, h)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_ylim(0)\n",
    "\n",
    "    ax_pops = fig.add_subplot(gs[1])\n",
    "\n",
    "    x_pop = labels_for_pop_colours.take(r['leaves'])\n",
    "    hap_pop_clrs = [pop_colour_scheme[p] for p in x_pop]\n",
    "    ax_pops.broken_barh(xranges=[(i, 1) for i in range(h.shape[1])],\n",
    "                        yrange=(0, 1),\n",
    "                        color=hap_pop_clrs);\n",
    "    sns.despine(ax=ax_pops, offset=5, left=True, bottom=True)\n",
    "    \n",
    "    ax_pops.set_xticks([])\n",
    "    ax_pops.set_yticks([])\n",
    "    ax_pops.set_xlim(0, h.shape[1])\n",
    "    ax_pops.yaxis.set_label_position('left')\n",
    "    ax_pops.set_ylabel('Population', rotation=0, ha='right', va='center')\n",
    "    \n",
    "    ax_cnv = fig.add_subplot(gs[2])\n",
    "\n",
    "    x_cnv = labels_for_cnv_colours.take(r['leaves'])\n",
    "    hap_cnv_clrs = [cnv_colour_scheme[p] for p in x_cnv]\n",
    "    ax_cnv.broken_barh(xranges=[(i, 1) for i in range(h.shape[1])],\n",
    "                       yrange=(0, 1),\n",
    "                       color=hap_cnv_clrs);\n",
    "    sns.despine(ax=ax_cnv, offset=5, left=True, bottom=True, top=True)\n",
    "\n",
    "    ax_cnv.set_xticks([])\n",
    "    ax_cnv.set_yticks([])\n",
    "    ax_cnv.set_xlim(0, h.shape[1])\n",
    "    ax_cnv.yaxis.set_label_position('left')\n",
    "    ax_cnv.set_ylabel(cnv_name, rotation=0, ha='right', va='center')\n",
    "\n",
    "    if add_legend:\n",
    "        plot_x_range = ax1.get_xlim()[1] - ax1.get_xlim()[0]\n",
    "        plot_y_range = ax1.get_ylim()[1] - ax1.get_ylim()[0]\n",
    "        legend_x = ax1.get_xlim()[0] + plot_x_range * 0.95\n",
    "            \n",
    "        unique_label_cnv = np.unique(x_cnv)\n",
    "        for i, k in enumerate(unique_label_cnv[::-1]):\n",
    "            legend_y = ax1.get_ylim()[0] + plot_y_range * (0.2 + 0.1 * i)\n",
    "            ax1.add_patch(mpl.patches.Rectangle((legend_x,legend_y), plot_x_range/50,plot_y_range/15, color = cnv_colour_scheme[k]))\n",
    "            ax1.text(legend_x*1.03,legend_y + plot_y_range / 50, k)\n",
    "\n",
    "        \n",
    "        unique_label_pop = np.unique(x_pop)\n",
    "        for j, k in enumerate(unique_label_pop[::-1]):\n",
    "            legend_y = ax1.get_ylim()[0] + plot_y_range * (0.2 + 0.1 * (i + 2 + j))\n",
    "            ax1.add_patch(mpl.patches.Rectangle((legend_x,legend_y), plot_x_range/50,plot_y_range/15, color = pop_colour_scheme[k]))\n",
    "            ax1.text(legend_x*1.03,legend_y + plot_y_range / 50, k)\n",
    "\n",
    "\n",
    "\n",
    "    ax1.set_title(f'{title}')\n",
    "    ax1.autoscale()\n",
    "    fig.patch.set_alpha(1)\n",
    "    \n",
    "    if fn != None:\n",
    "        ext = re.sub('.*\\.', '', fn)\n",
    "        plt.savefig(fn, format = ext)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haplotype clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home in on the 500 SNPs around the region of interest\n",
    "focal_pos = 28548072 # Middle of the two genes Coeae1f and Coeae2f\n",
    "window_size = 500  # Measured in SNPs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_snp_index = np.argmin(np.abs(haps_Dup.variant_position - focal_pos).values)\n",
    "haptree_region_indices = range(nearest_snp_index - window_size//2, nearest_snp_index + window_size//2)\n",
    "haptree_region = '2L:' + '-'.join(haps_Dup.isel(variants = haptree_region_indices).variant_position.values[[0,-1]].astype('str'))\n",
    "loc_hap = hap_array_Dup[haptree_region_indices]\n",
    "# loc_hap is the haplotype array for just those 500 SNPs. \n",
    "\n",
    "# Calculate the distance matrix \n",
    "dist = allel.pairwise_distance(loc_hap, metric = 'hamming')\n",
    "site_filter = ag3.snp_calls(region=haptree_region, sample_sets=\"3.7\")['variant_filter_pass_arab']\n",
    "n_bases = np.sum(site_filter.values)\n",
    "dist_dxy = dist * loc_hap.n_variants / n_bases\n",
    "\n",
    "z = scipy.cluster.hierarchy.linkage(dist_dxy, method=\"complete\")\n",
    "r = scipy.cluster.hierarchy.dendrogram(\n",
    "        z, no_labels=True, count_sort=True,\n",
    "        color_threshold=0, no_plot=True,\n",
    "        above_threshold_color='k')\n",
    "\n",
    "# Now let's plot the haplotype clustering tree\n",
    "Dup_hap_status = np.array(['Dup absent', 'Dup present'])[Dup_hap_proxy]\n",
    "draw_hap_cluster_plot(z, r, loc_hap, \n",
    "                      pop_colour_scheme = pop_colours, \n",
    "                      cnv_colour_scheme = dup_colours,\n",
    "                      labels_for_pop_colours = hap_meta_Dup['location'], \n",
    "                      labels_for_cnv_colours = Dup_hap_status, \n",
    "                      cnv_name = 'Coeaexf_Dup2',\n",
    "                      title = 'Haplotypes around Coeaexf',\n",
    "                      fn = 'Coeaexf_haplotype_clustering.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we don't have a SNP with perfect correlation, let's try just looking at copy number of the SNP on the genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dup_status = np.array(['Dup absent', 'Dup present'])[discordant_read_calls['Coeaexf_Dup2'].astype('int')]\n",
    "Dup_status = np.array(['No CNV', '1 extra copy', '2 extra copies', '3 extra copies', '4 extra copies'])[np.repeat(Dup_copy_number, 2)]\n",
    "\n",
    "draw_hap_cluster_plot(z, r, loc_hap, \n",
    "                      pop_colour_scheme = pop_colours, \n",
    "                      cnv_colour_scheme = dup_colours,\n",
    "                      labels_for_pop_colours = hap_meta['location'], \n",
    "                      labels_for_cnv_colours = Dup_status, \n",
    "                      cnv_name = 'Coeaexf_Dup2',\n",
    "                      title = 'Haplotypes around Coeaexg',\n",
    "                      fn = 'Coeaexf_haplotype_clustering_copy_number.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are still members of the swept cluster that don't have the haplotype, which suggests that the CNV appeared on the existing swept cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we find correlated SNPs that aren't among the phased haplotypes\n",
    "snps = (\n",
    "    ag3.snp_calls(region = region, \n",
    "                   sample_sets = sample_sets)\n",
    "    .set_index(samples = 'sample_id')\n",
    "    .sel(samples = discordant_read_calls.index)\n",
    ")\n",
    "snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's a lot bigger than the haplotypes. \n",
    "# Let's start by removing SNPs that are non-segregating or singletons in this dataset\n",
    "gen_array = allel.GenotypeArray(snps.call_genotype)\n",
    "gen_ac = gen_array.count_alleles()\n",
    "gen_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_is_segregating = gen_ac.is_segregating()\n",
    "gen_segregating_ac = gen_ac[gen_is_segregating, :]\n",
    "gen_segregating_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_maf = 50\n",
    "keep_snp = np.max(gen_segregating_ac, 1) <= (gen_array.shape[1]*2 - min_maf)\n",
    "filtered_snps = snps.sel(variants = gen_is_segregating).sel(variants = keep_snp)\n",
    "filtered_snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to need a separate test for every allele, since you can't represent a genotype\n",
    "# with more than two alleles as a single number.\n",
    "def all_alleles_spearman(gen, thresh_allele_count = 100):\n",
    "    output = [0]*4\n",
    "    for i in range(4):\n",
    "        allele_gen = gen == i\n",
    "        if np.sum(allele_gen) < thresh_allele_count:\n",
    "            p = np.nan\n",
    "        else:\n",
    "            p = spearmanr(np.any(allele_gen, 1).astype('int'), Dup_calls)[0]\n",
    "        output[i] = p\n",
    "    return(np.array(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genotypes = filtered_snps.call_genotype.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_SNP_cor = np.array([all_alleles_spearman(all_genotypes[i, :, :]) for i in range(all_genotypes.shape[0])])\n",
    "gen_SNP_cor = np.nanmax(np.abs(gen_SNP_cor), 1)\n",
    "print(f'The maximum correlation coefficient with the Dup is {np.nanmax(gen_SNP_cor)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not much better than when looking at phased haplotypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malariagen_latest",
   "language": "python",
   "name": "malariagen_latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
